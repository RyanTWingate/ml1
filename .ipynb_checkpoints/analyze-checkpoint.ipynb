{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('clean/adult_clean_norm_onehot.csv',\n",
    "                index_col='idx')\n",
    "t = pd.read_csv('clean/titanic_clean_norm_onehot.csv',\n",
    "                index_col='idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_data(which='a', size=None):\n",
    "    dataset = a.copy()\n",
    "    if which != 'a':\n",
    "        dataset = t.copy()\n",
    "    if size is not None:\n",
    "        dataset = dataset[:size].copy()\n",
    "    last_col = len(dataset.columns)-1\n",
    "    \n",
    "    X = dataset.drop(columns=dataset.columns[last_col])\n",
    "    y = dataset[[dataset.columns[last_col]]]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=1)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_max_scores(test_scores_mean, train_scores_mean, param_name, param_range):\n",
    "    if param_name == 'Training Examples':\n",
    "        max_test_score = test_scores_mean[-1]\n",
    "        max_train_score = train_scores_mean[-1]\n",
    "        max_n = len(param_range)-1\n",
    "        \n",
    "    else:\n",
    "        max_n = 0\n",
    "        max_test_score = test_scores_mean[0]\n",
    "\n",
    "        for n, score in enumerate(test_scores_mean):\n",
    "            if score > max_test_score:\n",
    "                max_test_score = score\n",
    "                max_n = n\n",
    "    \n",
    "    max_train_score = train_scores_mean[max_n]\n",
    "    delta = round(max_train_score*100,1) - round(max_test_score*100,1) \n",
    "    delta = round(delta,1)\n",
    "    \n",
    "    delta_state =     'Unacceptable'\n",
    "    if delta < 1.0:\n",
    "        delta_state = '  Acceptable'\n",
    "    elif delta <= 3.0:\n",
    "        delta_state = '    Marginal'\n",
    "    \n",
    "    print('        C.V. Score =', round(max_test_score*100,1), '@', param_name, '=', param_range[max_n])\n",
    "    print('    Training Score =', round(max_train_score*100,1))\n",
    "    print(delta_state, 'Delta =', delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(estimator, title, modifier,\n",
    "                          X_train, y_train, cv,\n",
    "                          ylim, param_name, param_range):\n",
    "    plt.figure(figsize=[8,9/2])\n",
    "    plt.title('Validation Curve' + ' - ' + title + '\\n' + modifier)\n",
    "    plt.ylim(*ylim)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('Score')\n",
    "\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X_train, y_train, param_name=param_name, param_range=param_range,\n",
    "        cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "        \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    \n",
    "    print_max_scores(test_scores_mean,\n",
    "                     train_scores_mean,\n",
    "                     param_name,\n",
    "                     param_range)\n",
    "    \n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color='darkorange')\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color='navy')\n",
    "    plt.plot(param_range, train_scores_mean, 'o-', color='darkorange',\n",
    "             label=\"Training score\")\n",
    "    plt.plot(param_range, test_scores_mean, 'o-', color='navy',\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, modifier,\n",
    "                        X_train, y_train, cv, \n",
    "                        ylim=None, train_sizes=None):\n",
    "    plt.figure(figsize=[8,9/2])\n",
    "    plt.title('Learning Curve' + ' - ' + title + '\\n' + modifier)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel('Training Examples')\n",
    "    plt.ylabel('Score')\n",
    "        \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X_train, y_train, cv=cv, n_jobs=-1, train_sizes=train_sizes)\n",
    "        \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    \n",
    "    print_max_scores(test_scores_mean,\n",
    "                     train_scores_mean,\n",
    "                     'Training Examples',\n",
    "                     train_sizes)\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(section_num, fig_num, fig):\n",
    "    path = 'report/figs/' + str(section_num) + '-' + str(fig_num) + '.png'\n",
    "    fig.savefig(path,\n",
    "                bbox_inches='tight',#)#,\n",
    "                pad_inches=0.375)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset and Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=10, \n",
    "                  test_size=0.2, \n",
    "                  random_state=1)\n",
    "lc_ylim=(0.7, 1.0)\n",
    "vc_ylim=(0.7, 1.0)\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = 'Decision Tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default criterion = 'gini'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "tree_est = tree.DecisionTreeClassifier(#criterion='entropy',\n",
    "                                       random_state=1)\n",
    "fig = plot_learning_curve(tree_est, learner, 'Default Hyperparameters',#\"criterion='entropy'\",\n",
    "                          X_train, y_train, cv=cv, ylim=lc_ylim, \n",
    "                          train_sizes=train_sizes)\n",
    "section_num = 1\n",
    "fig_num = 1\n",
    "save_fig(section_num, fig_num, fig)\n",
    "fig_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "tree_est = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                       random_state=1)\n",
    "fig = plot_learning_curve(tree_est, learner, \"criterion='entropy'\",\n",
    "                          X_train, y_train, cv=cv, ylim=lc_ylim, \n",
    "                          train_sizes=train_sizes)\n",
    "save_fig(section_num, fig_num, fig)\n",
    "fig_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "tree_est = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                       random_state=1)\n",
    "fig = plot_validation_curve(tree_est, learner, \"criterion='entropy'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='max_leaf_nodes', \n",
    "                            param_range=np.linspace(5, 50, 10, dtype=int))\n",
    "save_fig(section_num, fig_num, fig)\n",
    "fig_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "tree_est = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                       random_state=1)\n",
    "fig = plot_validation_curve(tree_est, learner, \"criterion='entropy'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='max_leaf_nodes', \n",
    "                            param_range=np.linspace(5, 14, 10, dtype=int))\n",
    "save_fig(section_num, fig_num, fig)\n",
    "fig_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "tree_est = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                       max_leaf_nodes=8,\n",
    "                                       random_state=1)\n",
    "fig = plot_learning_curve(tree_est, learner, \"criterion='entropy', max_leaf_nodes=8\",\n",
    "                          X_train, y_train, cv=cv, ylim=lc_ylim, \n",
    "                          train_sizes=train_sizes)\n",
    "save_fig(section_num, fig_num, fig)\n",
    "fig_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "tree_est = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                       random_state=1)\n",
    "fig = plot_learning_curve(tree_est, learner, \"criterion='entropy'\",#\n",
    "                          X_train, y_train, cv=cv, ylim=lc_ylim, \n",
    "                          train_sizes=train_sizes)\n",
    "section_num, fig_num = 2, 1\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "tree_est = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                       random_state=1)\n",
    "fig = plot_validation_curve(tree_est, learner, \"criterion='entropy'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='max_leaf_nodes', \n",
    "                            param_range=np.linspace(20, 200, 10, dtype=int))\n",
    "section_num, fig_num = 2, 2\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "tree_est = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                       max_leaf_nodes=100,\n",
    "                                       random_state=1)\n",
    "fig = plot_learning_curve(tree_est, learner, \"criterion='entropy', max_leaf_nodes=100\",\n",
    "                          X_train, y_train, cv=cv, ylim=lc_ylim, \n",
    "                          train_sizes=train_sizes)\n",
    "section_num, fig_num = 2, 3\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "tree_est = tree.DecisionTreeClassifier(criterion='gini',\n",
    "                                       max_leaf_nodes=100,\n",
    "                                       random_state=1)\n",
    "fig = plot_learning_curve(tree_est, learner, \"criterion='gini', max_leaf_nodes=100\",\n",
    "                          X_train, y_train, cv=cv, ylim=lc_ylim, \n",
    "                          train_sizes=train_sizes)\n",
    "#section_num, fig_num = 2, 4\n",
    "#save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = 'Multilayer Perceptron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default hidden_layer_sizes = (100,)\n",
    "# default activation = 'relu'\n",
    "# default solver = 'adam'\n",
    "# default max_iter = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "mlp_est = MLPClassifier(random_state=1)\n",
    "fig = plot_learning_curve(mlp_est, learner, \n",
    "                          \"Default Hyperparameters\",\n",
    "                          X_train, y_train, cv=cv, ylim=lc_ylim, \n",
    "                          train_sizes=train_sizes)\n",
    "section_num, fig_num = 3, 1\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default max_iter of 200, the classifer exhibits high bias, with a score of only roughly 65% on both training and cross-validation data.\n",
    "\n",
    "max_iter is the number of times a given data point can be used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "mlp_est = MLPClassifier(activation='logistic',\n",
    "                        solver='sgd',\n",
    "                        max_iter=2000,\n",
    "                        random_state=1)\n",
    "fig = plot_learning_curve(mlp_est, learner, \n",
    "                          \"activation='logistic', solver='sgd', max_iter=2000\",\n",
    "                          X_train, y_train, cv=cv, ylim=lc_ylim, \n",
    "                          train_sizes=train_sizes)\n",
    "section_num, fig_num = 3, 2\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "mlp_est = MLPClassifier(activation='logistic',\n",
    "                        solver='adam',\n",
    "                        max_iter=2000,\n",
    "                        random_state=1)\n",
    "fig =  plot_validation_curve(mlp_est, learner, \n",
    "                             \"activation='logistic', solver='adam', max_iter=2000\",\n",
    "                             X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                             param_name='hidden_layer_sizes', \n",
    "                             param_range=np.linspace(2, 20, 10, dtype=int))\n",
    "section_num, fig_num = 3, 3\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread in the following chart can be reduced by increasing the max_iter parameter, but the final values remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "mlp_est = MLPClassifier(activation='logistic',\n",
    "                        solver='adam',\n",
    "                        max_iter=2000,\n",
    "                        hidden_layer_sizes=(12),\n",
    "                        random_state=1)\n",
    "fig = plot_learning_curve(mlp_est, learner, \n",
    "                          \"activation='logistic', solver='adam', max_iter=2000, hidden_layer_sizes=(12)\",\n",
    "                          X_train, y_train, cv=cv, ylim=lc_ylim, \n",
    "                          train_sizes=train_sizes)\n",
    "section_num, fig_num = 3, 4\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3min 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "mlp_est = MLPClassifier(random_state=1)\n",
    "fig = plot_learning_curve(mlp_est, learner, \n",
    "                          \"Default Hyperparameters\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 4, 1\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~4min 30s~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "mlp_est = MLPClassifier(activation='logistic',\n",
    "                        solver='adam',\n",
    "                        random_state=1)\n",
    "fig = plot_learning_curve(mlp_est, learner, \n",
    "                          \"activation='logistic', solver='adam'\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 4, 2\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "mlp_est = MLPClassifier(activation='logistic',\n",
    "                        solver='adam',\n",
    "                        random_state=1)\n",
    "fig =  plot_validation_curve(mlp_est, learner, \n",
    "                             \"activation='logistic', solver='adam'\",\n",
    "                             X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                             param_name='hidden_layer_sizes', \n",
    "                             param_range=np.linspace(1, 20, 20, dtype=int))\n",
    "section_num, fig_num = 4, 3\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "mlp_est = MLPClassifier(activation='logistic',\n",
    "                        solver='adam',\n",
    "                        hidden_layer_sizes=17,\n",
    "                        random_state=1)\n",
    "fig = plot_learning_curve(mlp_est, learner, \n",
    "                          \"activation='logistic', solver='adam', hidden_layer_sizes=(17)\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 4, 4\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "# n_estimators = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = 'Single-Layer Decision Tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_est = tree.DecisionTreeClassifier(max_depth=1,\n",
    "                                       random_state=1)\n",
    "fig = plot_learning_curve(base_est, learner,\n",
    "                          \"Default Hyperparameters\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 5, 1\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = 'Boosted Single-Layer Decision Tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_est = AdaBoostClassifier(base_estimator=base_est,\n",
    "                               random_state=1)\n",
    "fig = plot_learning_curve(boost_est, learner, \n",
    "                          \"Default Hyperparameters\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 5, 2\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_est = AdaBoostClassifier(base_estimator=base_est,\n",
    "                               random_state=1)\n",
    "fig = plot_validation_curve(boost_est, learner, \n",
    "                            \"Default Hyperparameters\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='n_estimators', \n",
    "                            param_range=np.linspace(1, 15, 15, dtype=int))\n",
    "section_num, fig_num = 5, 3\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_est = AdaBoostClassifier(base_estimator=base_est,\n",
    "                               n_estimators=6,\n",
    "                               random_state=1)\n",
    "fig = plot_learning_curve(boost_est, learner, \n",
    "                          \"n_estimators=6\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 5, 4\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = 'Two-Layer Decision Tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_est = tree.DecisionTreeClassifier(max_depth=2,\n",
    "                                       random_state=1)\n",
    "fig = plot_learning_curve(base_est, learner, \n",
    "                          \"Default Hyperparameters\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 6, 1\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = 'Boosted Two-Layer Decision Tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_est = AdaBoostClassifier(base_estimator=base_est,\n",
    "                               random_state=1)\n",
    "fig = plot_validation_curve(boost_est, learner, \n",
    "                            \"Default Hyperparameters\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='n_estimators', \n",
    "                            param_range=np.linspace(5, 150, 30, dtype=int))\n",
    "section_num, fig_num = 6, 2\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boost_est = AdaBoostClassifier(base_estimator=base_est,\n",
    "                               n_estimators=55,\n",
    "                               random_state=1)\n",
    "fig = plot_learning_curve(boost_est, learner, \n",
    "                          \"n_estimators=55\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 6, 3\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = 'Support Vector Machine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nu = 0.5\n",
    "# kernel = 'rbf' other options = 'linear', 'poly', 'sigmoid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='rbf',\n",
    "                random_state=1)\n",
    "fig = plot_learning_curve(svc_est, learner, \n",
    "                          \"kernel='rbf'\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 7, 1\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='linear',\n",
    "                random_state=1)\n",
    "fig = plot_learning_curve(svc_est, learner, \n",
    "                          \"kernel='linear'\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 7, 2\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='poly',\n",
    "                random_state=1)\n",
    "fig = plot_learning_curve(svc_est, learner, \n",
    "                          \"kernel='poly'\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 7, 3\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='rbf',\n",
    "                random_state=1)\n",
    "fig = plot_validation_curve(svc_est, learner, \n",
    "                            \"kernel='rbf'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='nu', \n",
    "                            param_range=np.linspace(.05, .7, 14))\n",
    "section_num, fig_num = 7, 4\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='linear',\n",
    "                random_state=1)\n",
    "fig = plot_validation_curve(svc_est, learner, \n",
    "                            \"kernel='linear'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='nu', \n",
    "                            param_range=np.linspace(.05, .7, 14))\n",
    "section_num, fig_num = 7, 5\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='poly',\n",
    "                random_state=1)\n",
    "fig = plot_validation_curve(svc_est, learner, \n",
    "                            \"kernel='poly'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='degree', \n",
    "                            param_range=np.linspace(1,6,6,dtype=int))\n",
    "section_num, fig_num = 7, 7\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='poly',\n",
    "                degree=2,\n",
    "                random_state=1)\n",
    "fig = plot_validation_curve(svc_est, learner, \n",
    "                            \"kernel='poly', degree=2\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='nu', \n",
    "                            param_range=np.linspace(.05, .7, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='poly',\n",
    "                degree=2,\n",
    "                nu=.4,\n",
    "                random_state=1)\n",
    "fig = plot_learning_curve(svc_est, learner, \n",
    "                          \"kernel='poly', degree=2, nu=0.4\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 7, 8\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('a',\n",
    "                                               size=15625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='rbf',\n",
    "                random_state=1)\n",
    "fig = plot_validation_curve(svc_est, learner, \n",
    "                            \"kernel='rbf'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='nu', \n",
    "                            param_range=np.linspace(.05, .45, 9))\n",
    "section_num, fig_num = 8, 1\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='linear',\n",
    "                random_state=1)\n",
    "fig = plot_validation_curve(svc_est, learner, \n",
    "                            \"kernel='linear'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='nu', \n",
    "                            param_range=np.linspace(.05, .45, 9))\n",
    "section_num, fig_num = 8, 2\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='poly',\n",
    "                random_state=1)\n",
    "fig = plot_validation_curve(svc_est, learner, \n",
    "                            \"kernel='poly'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='nu', \n",
    "                            param_range=np.linspace(.05, .45, 9))\n",
    "section_num, fig_num = 8, 3\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='poly',\n",
    "                nu=0.45,\n",
    "                random_state=1)\n",
    "fig = plot_validation_curve(svc_est, learner, \n",
    "                            \"kernel='poly'\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='degree', \n",
    "                            param_range=np.linspace(1,6,6,dtype=int))\n",
    "section_num, fig_num = 8, 4\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='rbf',\n",
    "                nu=0.45,\n",
    "                random_state=1)\n",
    "fig = plot_learning_curve(svc_est, learner, \n",
    "                          \"kernel='rbf', nu=0.45\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 8, 5\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='poly',\n",
    "                degree=2,\n",
    "                random_state=1)\n",
    "fig = plot_validation_curve(svc_est, learner, \n",
    "                            \"kernel='poly', degree=2\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='nu', \n",
    "                            param_range=np.linspace(.05, .45, 9))\n",
    "#section_num, fig_num = 8, 5\n",
    "#save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_est = NuSVC(kernel='poly',\n",
    "                nu=0.45,\n",
    "                degree=2,\n",
    "                random_state=1)\n",
    "fig = plot_learning_curve(svc_est, learner, \n",
    "                          \"kernel='poly', degree=2, nu=0.45\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "#section_num, fig_num = 8, 6\n",
    "#save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = 'K-Nearest Neighbors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_neighbors = 5\n",
    "# p = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_est = KNeighborsClassifier()\n",
    "fig = plot_learning_curve(neigh_est, learner, \n",
    "                          \"Default Hyperparameters\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 9, 1\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_est = KNeighborsClassifier()\n",
    "fig = plot_validation_curve(neigh_est, learner, \n",
    "                            \"Default Hyperparameters\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='p', \n",
    "                            param_range=np.linspace(1, 3, 3, dtype=int))\n",
    "section_num, fig_num = 9, 2\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_est = KNeighborsClassifier(p=1)\n",
    "fig = plot_validation_curve(neigh_est, learner, \n",
    "                            \"p=1\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='n_neighbors', \n",
    "                            param_range=np.linspace(2, 30, 15, dtype=int))\n",
    "section_num, fig_num = 9, 3\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_est = KNeighborsClassifier(n_neighbors=28,\n",
    "                                 p=1)\n",
    "fig = plot_learning_curve(neigh_est, learner, \n",
    "                          \"n_neighbors=28, p=1\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 9, 4\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "neigh_est = KNeighborsClassifier()\n",
    "fig = plot_learning_curve(neigh_est, learner, \n",
    "                          \"Default Hyperparameters\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 10, 1\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "neigh_est = KNeighborsClassifier()\n",
    "fig = plot_validation_curve(neigh_est, learner, \n",
    "                            \"Default Hyperparameters\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='p', \n",
    "                            param_range=np.linspace(1, 3, 3, dtype=int))\n",
    "section_num, fig_num = 10, 2\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "neigh_est = KNeighborsClassifier(p=1)\n",
    "fig = plot_validation_curve(neigh_est, learner, \n",
    "                            \"p=1\",\n",
    "                            X_train, y_train, cv=cv, ylim=vc_ylim, \n",
    "                            param_name='n_neighbors', \n",
    "                            param_range=np.linspace(10, 100, 10, dtype=int))\n",
    "section_num, fig_num = 10, 3\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_est = KNeighborsClassifier(p=1,n_neighbors=60)\n",
    "fig = plot_learning_curve(neigh_est, learner, \n",
    "                          \"p=1, n_neighbors=60\",\n",
    "                          X_train, y_train, cv=cv, \n",
    "                          ylim=lc_ylim, train_sizes=train_sizes)\n",
    "section_num, fig_num = 10, 4\n",
    "save_fig(section_num, fig_num, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    print(\"Training: \", round(train_score*100.,1))\n",
    "    print(\" Testing: \", round(test_score*100.,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1 = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                  max_leaf_nodes=8,\n",
    "                                  random_state=1)\n",
    "clf = clone(clf_1)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = MLPClassifier(activation='logistic',\n",
    "                    solver='adam',\n",
    "                    max_iter=2000,\n",
    "                    hidden_layer_sizes=12,\n",
    "                    random_state=1)\n",
    "clf = clone(clf_2)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_est = tree.DecisionTreeClassifier(max_depth=1,\n",
    "                                       random_state=1)\n",
    "clf_3 = AdaBoostClassifier(base_estimator=base_est,\n",
    "                           n_estimators=6,\n",
    "                           random_state=1)\n",
    "clf = clone(clf_3)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_4 = NuSVC(kernel='poly',\n",
    "              nu=.4,\n",
    "              degree=2,\n",
    "              random_state=1)\n",
    "clf = clone(clf_4)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_5 = KNeighborsClassifier(n_neighbors=28,\n",
    "                             p=1)\n",
    "clf = clone(clf_5)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_6 = tree.DecisionTreeClassifier(criterion='entropy',\n",
    "                                    max_leaf_nodes=100,\n",
    "                                    random_state=1)\n",
    "clf = clone(clf_6)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_7 = MLPClassifier(activation='logistic',\n",
    "                      solver='adam',\n",
    "                      hidden_layer_sizes=17,\n",
    "                      random_state=1)\n",
    "clf = clone(clf_7)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_est = tree.DecisionTreeClassifier(max_depth=2,\n",
    "                                       random_state=1)\n",
    "clf_8 = AdaBoostClassifier(base_estimator=base_est,\n",
    "                           n_estimators=55,\n",
    "                           random_state=1)\n",
    "clf = clone(clf_8)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_9 = NuSVC(kernel='poly',\n",
    "              nu=0.45,\n",
    "              degree=2,\n",
    "              random_state=1)\n",
    "clf = clone(clf_9)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_10 = KNeighborsClassifier(n_neighbors=60,\n",
    "                              p=1)\n",
    "clf = clone(clf_10)\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Times\n",
    "\n",
    "Also do training iterations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clone(clf_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml1/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=12, learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2 = MLPClassifier(activation='logistic',\n",
    "                    solver='adam',\n",
    "                    max_iter=2000,\n",
    "                    hidden_layer_sizes=12,\n",
    "                    random_state=1)\n",
    "clf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subset_data('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml1/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=17, learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_7 = MLPClassifier(activation='logistic',\n",
    "                      solver='adam',\n",
    "                      hidden_layer_sizes=17,\n",
    "                      random_state=1)\n",
    "clf_7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_7.n_iter_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
